\section{Gradient Descent and Backpropagation}
\label{GD}

As explained in section \ref{sub:ClassProb}, classifiers try to choose their parameters ($\theta$) in order to minimize some pre-specified loss function.
In this work, we will work with the Mean-squared Error loss function as defined in equation \ref{LMSE}.

\subsection{Batch Gradient Descent}
\label{sub:BGD}

To optimize the loss function, we will use the Gradient Descent algorithm which in its most basic form takes the derivative of the cost function w.r.t. all the parameter values and updates the parameters by a value proportional to this gradient and opposite in sign.
A naive implementation of Gradient Descent is as shown in algorithm \ref{alg:BGD}.
\begin{algorithm}[tb]
   \caption{Batch Gradient Descent}
   \label{alg:BGD}
\begin{algorithmic}
   \STATE {\bfseries Input:} Dataset $\mathcal{D} = \{x^{(i)},y^{(i)}\}_{i=1:N}$, Step Size $\alpha$, Max Epochs $N_{epoch}$
   \STATE {\bfseries Output:} Parameters $\{\theta_k\}_{k=1:K}$
   \STATE
   \STATE Initialize $\theta$ randomly with small real numbers
   \STATE $ep := 0$
   \REPEAT
   \STATE $ep := ep + 1$
   \FOR {$k \in \{1:K\}$}
   \STATE $\frac{\partial \mathcal{L}_{MSE}}{\partial \theta_k} = \frac{1}{N} \sum_{i=1}^N ( y^{(i)} - f(x^{(i)}; \theta)) \frac{\partial f(x^{(i)}; \theta)}{\partial \theta_k}$
   \ENDFOR
   \STATE $\theta_k := \theta_k - \alpha \frac{\partial \mathcal{L}_{MSE}}{\partial \theta_k} \hspace{16pt} \forall k \in \{1:K\}$
   \UNTIL{$ep \geq N_{epoch}$}
\end{algorithmic}
\end{algorithm}

\subsection{Minibatch Gradient Descent}
\label{sub:MGD}

Note that the derivative of $\mathcal{L}_{MSE}$ in algorithm \ref{alg:BGD} requires us to sum over all the training examples.
This makes gradient computation, the biggest bottleneck for many supervised learning tasks on huge data sets.
One solution to this problem is to approximate the gradient with a smaller batch of training examples selected from the full dataset, so that more updates can be made in a smaller amount of time.
The resulting algorithm is called Minibatch Gradient Descent (abbreviated as MGD) and is shown in algorithm \ref{alg:MGD}.
\begin{algorithm}[tb]
   \caption{Minibatch Gradient Descent}
   \label{alg:MGD}
\begin{algorithmic}
   \STATE {\bfseries Input:} Dataset $\mathcal{D} = \{x^{(i)},y^{(i)}\}_{i=1:N}$, Step Size $\alpha$, Max Epochs $N_{epoch}$, Batch Size $B$
   \STATE {\bfseries Output:} Parameters $\{\theta_k\}_{k=1:K}$
   \STATE
   \STATE Initialize $\theta$ randomly with small real numbers
   \STATE $ep := 0$
   \REPEAT
   \STATE $ep := ep + 1$
   \STATE Divide $\mathcal{D}$ into batches $\{B_j\}_{j=1:\frac{N}{B}}$ of size $B$ each
   \FOR {$j \in \{1:\frac{N}{B}\}$}
   \FOR {$k \in \{1:K\}$}
   \STATE $\frac{\partial \mathcal{L}_{MSE}}{\partial \theta_k} = \frac{1}{B} \sum_{i \in B_j} ( y^{(i)} - f(x^{(i)}; \theta)) \frac{\partial f(x^{(i)}; \theta)}{\partial \theta_k}$
   \ENDFOR
   \STATE $\theta_k := \theta_k - \alpha \frac{\partial \mathcal{L}_{MSE}}{\partial \theta_k} \hspace{16pt} \forall k \in \{1:K\}$
   \ENDFOR
   \UNTIL{$ep \geq N_{epoch}$}
\end{algorithmic}
\end{algorithm}

\subsection{Backpropagation}
\label{sub:BackProp}

It can be seen that a major subroutine in algorithms \ref{alg:BGD} and \ref{alg:MGD} is the computation of gradient of the loss function for a single training example.

Since the neural network is a very complicated function comprising of many layered operations, the gradient of loss function is not trivial to compute.
For fully connected feedforward neural networks, first a forward pass is made to compute the value of neural network activations for all layers as shown in algorithm \ref{alg:FwdPass}. Then the gradient is computed by starting from the output layer and backpropagating gradient information for previous layers using the derivative chain-rule.

This procedure results in the famous \textit{backpropagation} algorithm to compute the gradient described briefly as follows:
Let $x$ be a training example with label $y$. Our feedforward neural network has an input layer and $L-1$ fully connected layers with sigmoid activation function. The parameters $\theta$ are all the neural network parameters i.e. $\theta = [W_{\{2:L\}}, b_{\{2:L\}}]$. We will use the Mean-Squared Error loss function:
\begin{align}
\mathcal{L}_{MSE} ([W_{\{2:L\}}, b_{\{2:L\}}]) = \frac{1}{N} \sum_{i=1}^N ( y - a_L(x))^2
\end{align}
where $a_L(x)$ is the activation of the output layer when the input to the neural network is $x$ and the network parameters are $[W_{\{2:L\}}, b_{\{2:L\}}]$.
The backpropagation algorithm first computes errors $\delta_l \in \mathbb{R}^{n_l}$ and then computes the derivative of loss function with respect to parameters as shown in algorithm \ref{alg:BackProp} \cite{Conway2000}. Note that $a \circ b$ is the elementwise product between vectors $a$ and $b$.
\begin{algorithm}[tb]
   \caption{Forward Propagation}
   \label{alg:FwdPass}
\begin{algorithmic}
   \STATE {\bfseries Input:} Example $x$, parameters $[W_{\{2:L\}}, b_{\{2:L\}}]$
   \STATE {\bfseries Output:} $z_l(x), a_l(x) \hspace{16pt} \forall l=1:L$
   \STATE
   \STATE $z_1(x) := x, a_1(x) := x$
   \FOR {$l=2:L$}
   \STATE $z_l(x) = (W_l)^T a_{l-1}(x) + b_l$
   \STATE $a_l(x) = \sigma(z_l)$
   \ENDFOR
\end{algorithmic}
\end{algorithm}
\begin{algorithm}[tb]
   \caption{Backpropagation}
   \label{alg:BackProp}
\begin{algorithmic}
   \STATE {\bfseries Input:} Example $x$, label $y$, parameters $[W_{\{2:L\}}, b_{\{2:L\}}]$
   \STATE {\bfseries Output:} Derivatives $\{\frac{\partial \mathcal{L}_{MSE}}{\partial b_l}\}_{l=2:L}, \{\frac{\partial \mathcal{L}_{MSE}}{\partial W_l}\}_{l=2:L}$
   \STATE
   \STATE Compute $z_l(x), a_l(x) \hspace{4pt} \forall l=1:L$ with a forward pass
   \STATE $\delta_L := \frac{\partial \mathcal{L}_{MSE}}{\partial a_L} \circ \sigma'(z_L(x))$
   \FOR {$l=L:2$}
   \STATE $\frac{\partial \mathcal{L}_{MSE}}{\partial b_l} := \delta_l$
   \STATE $\frac{\partial \mathcal{L}_{MSE}}{\partial W_l} := a_{l-1} \delta_l^T$
   \STATE $\delta_{l-1} := (W_l \delta_l) \circ \sigma'(z_{l-1}(x))$
   \ENDFOR
\end{algorithmic}
\end{algorithm}